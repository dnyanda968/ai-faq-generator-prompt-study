# AI FAQ Generator Prompt Study

This project explores how prompt engineering affects the quality of FAQ extraction from a policy document.

## ğŸ“‚ Project Structure

- `sample_input.txt` â€“ Example company policy document.
- `Prompts.pdf` â€“ Three prompt variations.
- `Outputs/` â€“ Outputs generated for each prompt.

## ğŸ’¡ Overview

I tested three prompt styles:

1. **Simple Q&A** â€“ Basic extraction of questions and answers.
2. **Detailed Q&A** â€“ More specific, thorough responses.
3. **Markdown Table** â€“ Structured output in table format.

## ğŸ› ï¸ Tools Used

- ChatGPT for prompt testing
- GitHub for version control

## âœ¨ Key Learnings

- Prompt specificity increases the detail in outputs.
- Output formatting instructions affect readability.
- Iterating on prompts improves clarity.

